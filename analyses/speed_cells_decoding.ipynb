{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe24a771",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a6af65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind, wilcoxon, mannwhitneyu\n",
    "from matplotlib.gridspec import GridSpec, GridSpecFromSubplotSpec\n",
    "from matplotlib.patches import Patch\n",
    "from itertools import combinations\n",
    "from scipy.stats.mstats import winsorize\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d93fb5",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28e677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to extract value from single-key dictionaries\n",
    "def extract_value(value):\n",
    "    if isinstance(value, dict) and \"col_1\" in value:\n",
    "        return value[\"col_1\"]\n",
    "    return value\n",
    "\n",
    "# Load JSON data\n",
    "json_file_path = 'data.json'  # Replace with actual file path\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Define a mapping of column names to more descriptive names\n",
    "column_mapping = {\n",
    "    \"col_1\": \"Rat_Session\",\n",
    "    \"col_2\": \"Tetrode_ID\",\n",
    "    \"col_3\": \"Neuron_ID\",\n",
    "    \"col_4\": \"Firing_Rate_Data\",\n",
    "    \"col_5\": \"Speed_Vector\",\n",
    "    \"col_6\": \"Neuron_Classification\",\n",
    "    \"col_7\": \"Mean_Firing_Rate\",\n",
    "    \"col_8\": \"Locomotion_Cell\",\n",
    "    \"col_9\": \"CCG_Value\"\n",
    "}\n",
    "\n",
    "# Define a mapping for the nested Firing_Rate_Data columns\n",
    "firing_rate_mapping = {\n",
    "    \"col_1\": \"Firing_Rate\",\n",
    "    \"col_2\": \"Position_Bins\",\n",
    "    \"col_3\": \"Correct_Choices\",\n",
    "    \"col_4\": \"Cue_Type\",\n",
    "    \"col_5\": \"Arm_Choice\",\n",
    "    \"col_6\": \"Trial_Number\"\n",
    "}\n",
    "\n",
    "# Convert JSON to a structured DataFrame\n",
    "rows = []\n",
    "for row_key, row_data in data.items():\n",
    "    row = {}\n",
    "    for col_key, col_value in row_data.items():\n",
    "        # Map to the descriptive name if available\n",
    "        descriptive_name = column_mapping.get(col_key, col_key)\n",
    "        if descriptive_name == \"Firing_Rate_Data\" and isinstance(col_value, dict):\n",
    "            # Expand the nested dictionary\n",
    "            for nested_key, nested_value in col_value.items():\n",
    "                nested_name = firing_rate_mapping.get(nested_key, nested_key)\n",
    "                row[nested_name] = extract_value(nested_value)\n",
    "        else:\n",
    "            row[descriptive_name] = extract_value(col_value)\n",
    "    rows.append(row)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "# map neuron classification from 21 and 22 to 1 and -1\n",
    "df['Neuron_Classification'] = df['Neuron_Classification'].map({21: 1, 22: -1})\n",
    "\n",
    "# List of columns to convert (columns 3-9)\n",
    "numeric_columns = [\n",
    "    'Neuron_ID',\n",
    "    'Firing_Rate',\n",
    "    'Position_Bins', \n",
    "    'Correct_Choices',\n",
    "    'Cue_Type',\n",
    "    'Arm_Choice',\n",
    "    'Trial_Number',\n",
    "    'CCG_Value'\n",
    "]\n",
    "\n",
    "# Convert specified columns to numpy arrays\n",
    "for col in numeric_columns:\n",
    "    df[col] = df[col].apply(np.array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18315292",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080ad83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize_data(X, y, limits=[0.05, 0.05]):\n",
    "    \"\"\"\n",
    "    Apply winsorization to both X and y data arrays to limit extreme values.\n",
    "\n",
    "    Winsorization replaces extreme values with less extreme values by setting\n",
    "    values below and above specified percentiles to those percentile values.\n",
    "    This helps reduce the impact of outliers while preserving data structure.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like\n",
    "        Input array of predictor variables to be winsorized\n",
    "    y : array-like  \n",
    "        Input array of target variables to be winsorized\n",
    "    limits : tuple of float, optional (default=[0.05, 0.05])\n",
    "        Tuple of (lower, upper) percentages to cut on each tail.\n",
    "        E.g. (0.05, 0.05) means cut 5% on both tails.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    X_win : array-like\n",
    "        Winsorized version of input X array\n",
    "    y_win : array-like\n",
    "        Winsorized version of input y array\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Uses scipy.stats.mstats.winsorize under the hood.\n",
    "    Both arrays are winsorized independently using the same limits.\n",
    "    \"\"\"\n",
    "    \"\"\"Apply winsorization to both X and y data\"\"\"\n",
    "    X_win = winsorize(X, limits=limits)\n",
    "    y_win = winsorize(y, limits=limits)\n",
    "    return X_win, y_win"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2d58cf",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2144707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(df):\n",
    "    df['Speed_Vector'] = df['Speed_Vector'].apply(np.array)\n",
    "\n",
    "    # standardize the firing rates for each neuron\n",
    "    df['Firing_Rate_Standardized'] = df['Firing_Rate'].apply(stats.zscore)\n",
    "    \n",
    "    # standardize the speed vector for each neuron\n",
    "    df['Speed_Vector_Standardized'] = df['Speed_Vector'].apply(stats.zscore)\n",
    "\n",
    "    # apply a Gaussian filter to smooth the firing rates\n",
    "    df['Firing_Rate_Smoothed'] = df['Firing_Rate_Standardized'].apply(lambda x: gaussian_filter1d(x, sigma=10))\n",
    "    \n",
    "    # apply the same filter to the speed vector\n",
    "    df['Speed_Vector_Smoothed'] = df['Speed_Vector_Standardized'].apply(lambda x: gaussian_filter1d(x, sigma=10))\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df = process_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7791e32a",
   "metadata": {},
   "source": [
    "## Single speed cell surrogates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e22ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_chance_r2(cell_idx, df, model, kf, n_shuffles=100):\n",
    "    \"\"\"Computes the mean chance R2 score for a single cell using circular time shifts.\"\"\"\n",
    "    X_orig_circ = np.array(df.loc[cell_idx, 'Firing_Rate_Smoothed']).reshape(-1, 1)\n",
    "    y_orig_circ = np.array(df.loc[cell_idx, 'Firing_Rate_Smoothed'])\n",
    "\n",
    "    if len(X_orig_circ) == 0 or len(y_orig_circ) == 0 or len(X_orig_circ) != len(y_orig_circ) \\\n",
    "       or len(X_orig_circ) < kf.get_n_splits():\n",
    "        return np.nan\n",
    "\n",
    "    _, y_win = winsorize_data(y_orig_circ, y_orig_circ) # Winsorize speed once\n",
    "\n",
    "    shuffle_scores = []\n",
    "    data_len = len(X_orig_circ)\n",
    "    min_shift = int(data_len * 0.20)\n",
    "    max_shift = int(data_len * 0.50)\n",
    "    \n",
    "    if min_shift >= max_shift: # Handle short data\n",
    "        min_shift = 1\n",
    "        max_shift = max(1, data_len - 1)\n",
    "        if min_shift >= max_shift and data_len <= 1: return np.nan # Cannot shift\n",
    "\n",
    "    for _ in range(n_shuffles):\n",
    "        shift = np.random.randint(min_shift, max_shift + 1)\n",
    "        X_shifted = np.roll(X_orig_circ, shift)\n",
    "        X_shifted_win, _ = winsorize_data(X_shifted, X_shifted)\n",
    "        X_shifted_reshaped = X_shifted_win.reshape(-1, 1)\n",
    "\n",
    "        current_len = min(len(X_shifted_reshaped), len(y_win))\n",
    "        X_shifted_final = X_shifted_reshaped[:current_len]\n",
    "        y_win_matched = y_win[:current_len]\n",
    "\n",
    "        if len(y_win_matched) < kf.get_n_splits(): continue\n",
    "\n",
    "        try:\n",
    "            scores = cross_val_score(model, X_shifted_final, y_win_matched, cv=kf, scoring='r2')\n",
    "            shuffle_scores.append(np.mean(scores))\n",
    "        except ValueError: continue\n",
    "\n",
    "    return np.mean(shuffle_scores) if shuffle_scores else np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79e5a21",
   "metadata": {},
   "source": [
    "# Single-cell decoding pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400195b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model with polynomial features\n",
    "model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=3)),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Initialize list to store results\n",
    "results = []\n",
    "\n",
    "# Cross validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=777)\n",
    "\n",
    "# Train models for each cell\n",
    "for idx in df.index:\n",
    "    # Get cell info\n",
    "    cell_info = {\n",
    "        'Cell_Index': idx,\n",
    "        'Rat_Session': df.loc[idx, 'Rat_Session'],\n",
    "        'Tetrode_ID': df.loc[idx, 'Tetrode_ID'],\n",
    "        'Neuron_ID': df.loc[idx, 'Neuron_ID']\n",
    "    }\n",
    "    \n",
    "    # Prepare data\n",
    "    X = np.array(df.loc[idx, 'Firing_Rate_Smoothed']).reshape(-1, 1)\n",
    "    y = np.array(df.loc[idx, 'Speed_Vector_Smoothed'])\n",
    "\n",
    "    # Apply winsorization\n",
    "    X_win, y_win = winsorize_data(X.ravel(), y)\n",
    "    X_win = np.asarray(X_win).reshape(-1, 1)\n",
    "\n",
    "    cv_scores = cross_val_score(model, X_win, y_win, cv=kf, scoring='r2')\n",
    "\n",
    "    # Add scores to cell info\n",
    "    for fold, score in enumerate(cv_scores, 1):\n",
    "        cell_info[f'Fold_{fold}_R2'] = score\n",
    "    cell_info['Mean_R2'] = cv_scores.mean()\n",
    "    cell_info['Std_R2'] = cv_scores.std()\n",
    "    \n",
    "    results.append(cell_info)\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display summary\n",
    "print(\"Results DataFrame with Winsorized Data:\")\n",
    "print(results_df.head())\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(results_df[['Mean_R2', 'Std_R2']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56837966",
   "metadata": {},
   "source": [
    "## Compute the single speed cell surrogates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a5de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Chance R2 for Speed Cells ---\n",
    "speed_cell_indices = df[df['Locomotion_Cell'] == True].index\n",
    "chance_r2_results = {}\n",
    "print(\"\\nCalculating chance R2 scores for speed cells...\")\n",
    "for cell_idx in tqdm(speed_cell_indices):\n",
    "    if pd.notna(results_df.loc[cell_idx, 'Mean_R2']):\n",
    "        # Pass the correct model (single_cell_model)\n",
    "        chance_mean = compute_chance_r2(cell_idx, df, model, kf, n_shuffles=100)\n",
    "        chance_r2_results[cell_idx] = chance_mean\n",
    "    else:\n",
    "        chance_r2_results[cell_idx] = np.nan\n",
    "\n",
    "results_df['Chance_Mean_R2'] = results_df['Cell_Index'].map(chance_r2_results)\n",
    "\n",
    "# Stats for Speed Cells vs Chance ---\n",
    "speed_cell_actual_r2 = results_df.loc[results_df['Cell_Index'].isin(speed_cell_indices), 'Mean_R2'].dropna()\n",
    "speed_cell_chance_r2 = results_df.loc[results_df['Cell_Index'].isin(speed_cell_indices), 'Chance_Mean_R2'].dropna()\n",
    "\n",
    "common_indices = speed_cell_actual_r2.index.intersection(speed_cell_chance_r2.index)\n",
    "speed_cell_actual_r2 = speed_cell_actual_r2.loc[common_indices]\n",
    "speed_cell_chance_r2 = speed_cell_chance_r2.loc[common_indices]\n",
    "\n",
    "chance_comparison_stat, chance_comparison_pvalue = np.nan, np.nan # Initialize\n",
    "if len(speed_cell_actual_r2) > 0 and len(speed_cell_actual_r2) == len(speed_cell_chance_r2):\n",
    "     diff = speed_cell_actual_r2 - speed_cell_chance_r2\n",
    "     if np.all(np.isclose(diff, 0)):\n",
    "         print(\"Actual and Chance R2 scores are identical. Wilcoxon test not applicable.\")\n",
    "         chance_comparison_pvalue = 1.0\n",
    "     else:\n",
    "         try:\n",
    "              chance_comparison_stat, chance_comparison_pvalue = wilcoxon(speed_cell_actual_r2, speed_cell_chance_r2)\n",
    "              print(f\"\\nWilcoxon test: Speed Cells Actual R2 vs. Chance R2\")\n",
    "              print(f\"Statistic: {chance_comparison_stat:.3f}, P-value: {chance_comparison_pvalue:.3e}\")\n",
    "         except ValueError as e: # Fallback if Wilcoxon fails\n",
    "              print(f\"Wilcoxon failed ('{e}'), falling back to paired t-test.\")\n",
    "              try:\n",
    "                  chance_comparison_stat, chance_comparison_pvalue = stats.ttest_rel(speed_cell_actual_r2, speed_cell_chance_r2)\n",
    "                  print(f\"Paired t-test: Stat={chance_comparison_stat:.3f}, P-value={chance_comparison_pvalue:.3e}\")\n",
    "              except Exception as te:\n",
    "                   print(f\"Paired t-test also failed: {te}\")\n",
    "else:\n",
    "     print(\"Not enough valid paired data points for Speed Cell vs Chance comparison.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef61c529",
   "metadata": {},
   "source": [
    "# Single-cell decoding stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fba9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for speed cells first, then by neuron classification\n",
    "speed_cell_mask = df['Locomotion_Cell'] == True\n",
    "fsi_data = results_df[(df['Neuron_Classification'] == -1) & speed_cell_mask]['Mean_R2'].dropna().values # Fast-spiking interneurons that are speed cells\n",
    "msn_data = results_df[(df['Neuron_Classification'] == 1) & speed_cell_mask]['Mean_R2'].dropna().values # Medium spiny neurons that are speed cells\n",
    "other_data = results_df[df['Locomotion_Cell'] == False]['Mean_R2'].dropna().values # Non-speed cells\n",
    "speed_data = results_df[df['Locomotion_Cell'] == True]['Mean_R2'].dropna().values # Actual R2\n",
    "speed_chance_data = results_df[df['Locomotion_Cell'] == True]['Chance_Mean_R2'].dropna().values # Chance R2\n",
    "\n",
    "neuron_ttest = stats.ttest_ind(fsi_data, msn_data, nan_policy='omit') # Fast-spiking vs Medium spiny\n",
    "loco_ttest = stats.ttest_ind(other_data, speed_data, nan_policy='omit') # Non-speed vs Speed cells\n",
    "# chance_comparison stat/pvalue already calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845e269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of Positive vs Negative CCG Cells\n",
    "\n",
    "mean_r2_by_cell = results_df.set_index('Cell_Index')['Mean_R2']\n",
    "\n",
    "# Use CCG_Value instead of Optimal_Lag to define positive/negative cells\n",
    "pos_idx = df[(df['Locomotion_Cell'] == True) & (df['CCG_Value'] >= 0)].index\n",
    "neg_idx = df[(df['Locomotion_Cell'] == True) & (df['CCG_Value'] < 0)].index\n",
    "\n",
    "pos_r2 = mean_r2_by_cell.reindex(pos_idx).dropna().values\n",
    "neg_r2 = mean_r2_by_cell.reindex(neg_idx).dropna().values\n",
    "\n",
    "# Statistical test: Mann-Whitney U (nonparametric, two independent groups)\n",
    "pos_neg_p = np.nan\n",
    "pos_neg_stat = np.nan\n",
    "if len(pos_r2) > 0 and len(neg_r2) > 0:\n",
    "    pos_neg_stat, pos_neg_p = mannwhitneyu(pos_r2, neg_r2, alternative='two-sided')\n",
    "    print(f\"Positive vs Negative CCG Mann-Whitney U p-value: {pos_neg_p:.3e}, U={pos_neg_stat:.3f}\")\n",
    "    print(f\"Positive CCG cells: {len(pos_r2)}, Negative CCG cells: {len(neg_r2)}\")\n",
    "else:\n",
    "    print(\"Positive vs Negative CCG comparison: not enough data (pos:\", len(pos_r2), \"neg:\", len(neg_r2), \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a303aa",
   "metadata": {},
   "source": [
    "# Multi-cell decoding pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e121de59",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0fe9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_combination(cell_indices, df):\n",
    "    \"\"\"\n",
    "    Validates if selected cells from the DataFrame have compatible data lengths.\n",
    "    This function checks if the firing rate vectors for all selected cells have the same length,\n",
    "    and if the speed vector matches this length. This validation is crucial for ensuring \n",
    "    data consistency before further analysis.\n",
    "    Parameters\n",
    "    ----------\n",
    "    cell_indices : list or array-like\n",
    "        List of cell indices to validate from the DataFrame\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing the neural recording data with columns:\n",
    "        - 'CircLagged_Firing_Rate': firing rate vectors for each cell\n",
    "        - 'CircLagged_Speed': speed vector for each cell\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if all vectors have matching lengths\n",
    "        False if any length mismatch is found\n",
    "    Examples\n",
    "    --------\n",
    "    >>> cell_ids = [0, 1, 2]\n",
    "    >>> result = validate_combination(cell_ids, neural_data_df)\n",
    "    >>> if result:\n",
    "    ...     print(\"Data lengths are compatible\")\n",
    "    ... else:\n",
    "    ...     print(\"Data lengths mismatch\")\n",
    "    Notes\n",
    "    -----\n",
    "    The function performs two checks:\n",
    "    1. Verifies that all firing rate vectors have the same length\n",
    "    2. Confirms that the speed vector matches the firing rate vector length\n",
    "    \"\"\"\n",
    "    # Check if all firing rate vectors have the same length\n",
    "    firing_rate_lengths = [len(df.loc[cell_idx, 'Firing_Rate_Smoothed']) for cell_idx in cell_indices]\n",
    "    if len(set(firing_rate_lengths)) != 1:\n",
    "        print(f\"Error: Firing rate vectors have different lengths for cells {cell_indices}\")\n",
    "        return False\n",
    "    \n",
    "    # Check if speed vector has the same length as firing rate vectors\n",
    "    speed_length = len(df.loc[cell_indices[0], 'Speed_Vector_Smoothed'])\n",
    "    if speed_length != firing_rate_lengths[0]:\n",
    "        print(f\"Error: Speed vector has different length for cells {cell_indices}\")\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984eabd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_r2_scores(cell_indices, df, cv=kf):\n",
    "    \"\"\"\n",
    "    Compute cross-validated R² for a combination of cells WITHOUT time-lag features.\n",
    "    Each cell contributes a single column (winsorized firing rate). Uses cross_val_score.\n",
    "    Returns array of CV fold R² scores or array([np.nan]) if not computable.\n",
    "    \"\"\"\n",
    "    # collect winsorized firing-rate columns\n",
    "    X_cols = []\n",
    "    for cell_idx in cell_indices:\n",
    "        X_temp = np.array(df.loc[cell_idx, 'Firing_Rate_Smoothed']).ravel()\n",
    "        X_win, _ = winsorize_data(X_temp, X_temp)\n",
    "        X_cols.append(np.asarray(X_win).ravel())\n",
    "\n",
    "    # stack columns -> shape (n_samples, n_cells)\n",
    "    X_final = np.column_stack(X_cols)\n",
    "\n",
    "    # target (use first cell's speed vector; validate_combination2 ensures lengths match)\n",
    "    y = np.array(df.loc[cell_indices[0], 'Speed_Vector_Smoothed']).ravel()\n",
    "    _, y_win = winsorize_data(y, y)\n",
    "    y_final = y_win[:len(X_final)]  # safety trim if needed\n",
    "\n",
    "    # require enough samples for CV\n",
    "    n_splits = getattr(cv, \"get_n_splits\", lambda *a, **k: 1)()\n",
    "    if len(y_final) < n_splits or X_final.shape[0] < n_splits:\n",
    "        return np.array([np.nan])\n",
    "\n",
    "    try:\n",
    "        scores = cross_val_score(model, X_final, y_final, cv=cv, scoring='r2', n_jobs=None)\n",
    "        return scores\n",
    "    except Exception:\n",
    "        return np.array([np.nan])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52366992",
   "metadata": {},
   "source": [
    "## Compute the decoding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c4baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_pipeline = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=3)),\n",
    "    ('regressor', Ridge(alpha=1.0))\n",
    "])\n",
    "\n",
    "r2_data = {n: [] for n in range(1, 6)}\n",
    "\n",
    "mean_r2_series = results_df.set_index('Cell_Index')['Mean_R2']\n",
    "df['SingleCell_R2'] = mean_r2_series\n",
    "session_groups = df.groupby('Rat_Session').groups\n",
    "# compute total_combinations\n",
    "total_combinations = 0\n",
    "for session, cell_indices in session_groups.items():\n",
    "    session_cells = list(cell_indices)\n",
    "    filtered_speed = [\n",
    "        idx for idx in session_cells\n",
    "        if df.loc[idx, 'Locomotion_Cell']\n",
    "        and pd.notna(df.loc[idx, 'SingleCell_R2'])\n",
    "        and df.loc[idx, 'SingleCell_R2'] >= 0.1\n",
    "    ]\n",
    "    for n_cells in range(1, min(6, len(filtered_speed) + 1)):\n",
    "        total_combinations += math.comb(len(filtered_speed), n_cells)\n",
    "\n",
    "with tqdm(total=total_combinations, desc=\"Computing R² scores\") as pbar:\n",
    "    for session, cell_indices in session_groups.items():\n",
    "        session_cells = list(cell_indices)\n",
    "        filtered_speed = [\n",
    "            idx for idx in session_cells\n",
    "            if df.loc[idx, 'Locomotion_Cell']\n",
    "            and pd.notna(df.loc[idx, 'SingleCell_R2'])\n",
    "            and df.loc[idx, 'SingleCell_R2'] >= 0.1\n",
    "        ]\n",
    "        for n_cells in range(1, min(6, len(filtered_speed) + 1)):\n",
    "            for cell_combination in combinations(filtered_speed, n_cells):\n",
    "                if validate_combination(cell_combination, df):\n",
    "                    scores = compute_r2_scores(cell_combination, df, cv=kf)\n",
    "                    if np.all(np.isnan(scores)):\n",
    "                        r2_data[n_cells].append(np.nan)\n",
    "                    else:\n",
    "                        r2_data[n_cells].append(np.median(scores))\n",
    "                pbar.update(1)\n",
    "\n",
    "print(\"\\nNumber of valid combinations by group size:\")\n",
    "print(\"-\" * 40)\n",
    "for n_cells, scores in r2_data.items():\n",
    "    print(f\"Number of combinations for {n_cells} cells: {len(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17708b30",
   "metadata": {},
   "source": [
    "## Multi-cell decoding surrogates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debbf3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_multi_cell_chance_r2(cell_indices, df, model, kf, n_shuffles=100):\n",
    "    \"\"\"\n",
    "    Computes the mean chance R2 score for a combination of cells using circular time shifts.\n",
    "    All firing rate vectors are shifted by the same amount to preserve inter-neuronal relationships\n",
    "    while destroying the relationship with speed.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cell_indices : list\n",
    "        List of cell indices to include in the multi-cell analysis\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing neural data\n",
    "    model : sklearn.pipeline.Pipeline\n",
    "        Machine learning model for decoding\n",
    "    kf : sklearn.model_selection.KFold\n",
    "        Cross-validation object\n",
    "    n_shuffles : int, default=100\n",
    "        Number of surrogate iterations\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Mean chance R² score across shuffles, or np.nan if computation fails\n",
    "    \"\"\"\n",
    "    # Validate combination first\n",
    "    if not validate_combination(cell_indices, df):\n",
    "        return np.nan\n",
    "    \n",
    "    # Collect original data\n",
    "    X_cols = []\n",
    "    for cell_idx in cell_indices:\n",
    "        X_temp = np.array(df.loc[cell_idx, 'Firing_Rate_Smoothed']).ravel()\n",
    "        X_win, _ = winsorize_data(X_temp, X_temp)\n",
    "        X_cols.append(np.asarray(X_win).ravel())\n",
    "    \n",
    "    X_orig = np.column_stack(X_cols)  # Shape: (n_samples, n_cells)\n",
    "    \n",
    "    # Get target speed vector\n",
    "    y_orig = np.array(df.loc[cell_indices[0], 'Speed_Vector_Smoothed']).ravel()\n",
    "    _, y_win = winsorize_data(y_orig, y_orig)\n",
    "    y_final = y_win[:len(X_orig)]\n",
    "    \n",
    "    # Check if we have enough data\n",
    "    if len(X_orig) == 0 or len(y_final) == 0 or len(X_orig) != len(y_final) or len(X_orig) < kf.get_n_splits():\n",
    "        return np.nan\n",
    "    \n",
    "    shuffle_scores = []\n",
    "    data_len = len(X_orig)\n",
    "    min_shift = int(data_len * 0.20)\n",
    "    max_shift = int(data_len * 0.50)\n",
    "    \n",
    "    # Handle short data\n",
    "    if min_shift >= max_shift:\n",
    "        min_shift = 1\n",
    "        max_shift = max(1, data_len - 1)\n",
    "        if min_shift >= max_shift and data_len <= 1:\n",
    "            return np.nan\n",
    "    \n",
    "    for _ in range(n_shuffles):\n",
    "        # Apply same shift to all firing rate vectors\n",
    "        shift = np.random.randint(min_shift, max_shift + 1)\n",
    "        X_shifted = np.roll(X_orig, shift, axis=0)  # Shift along time axis\n",
    "        \n",
    "        # Ensure same length\n",
    "        current_len = min(len(X_shifted), len(y_final))\n",
    "        X_shifted_final = X_shifted[:current_len]\n",
    "        y_final_matched = y_final[:current_len]\n",
    "        \n",
    "        if len(y_final_matched) < kf.get_n_splits():\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            scores = cross_val_score(model, X_shifted_final, y_final_matched, cv=kf, scoring='r2')\n",
    "            shuffle_scores.append(np.mean(scores))\n",
    "        except (ValueError, Exception):\n",
    "            continue\n",
    "    \n",
    "    return np.mean(shuffle_scores) if shuffle_scores else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe7d760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute surrogate R² for multi-cell combinations\n",
    "print(\"Computing surrogate R² scores for multi-cell combinations...\")\n",
    "\n",
    "multi_cell_chance_r2 = {n: [] for n in range(1, 6)}\n",
    "session_groups = df.groupby('Rat_Session').groups\n",
    "\n",
    "# Calculate total combinations for progress bar\n",
    "total_combinations_chance = 0\n",
    "for session, cell_indices in session_groups.items():\n",
    "    session_cells = list(cell_indices)\n",
    "    filtered_speed = [\n",
    "        idx for idx in session_cells\n",
    "        if df.loc[idx, 'Locomotion_Cell']\n",
    "        and pd.notna(df.loc[idx, 'SingleCell_R2'])\n",
    "        and df.loc[idx, 'SingleCell_R2'] >= 0.1\n",
    "    ]\n",
    "    for n_cells in range(1, min(6, len(filtered_speed) + 1)):\n",
    "        total_combinations_chance += math.comb(len(filtered_speed), n_cells)\n",
    "\n",
    "with tqdm(total=total_combinations_chance, desc=\"Computing multi-cell surrogate R² scores\") as pbar:\n",
    "    for session, cell_indices in session_groups.items():\n",
    "        session_cells = list(cell_indices)\n",
    "        filtered_speed = [\n",
    "            idx for idx in session_cells\n",
    "            if df.loc[idx, 'Locomotion_Cell']\n",
    "            and pd.notna(df.loc[idx, 'SingleCell_R2'])\n",
    "            and df.loc[idx, 'SingleCell_R2'] >= 0.1\n",
    "        ]\n",
    "        \n",
    "        for n_cells in range(1, min(6, len(filtered_speed) + 1)):\n",
    "            for cell_combination in combinations(filtered_speed, n_cells):\n",
    "                if validate_combination(cell_combination, df):\n",
    "                    if n_cells == 1:\n",
    "                        # For single cells, use existing single-cell surrogate if available\n",
    "                        cell_idx = cell_combination[0]\n",
    "                        if cell_idx in chance_r2_results and pd.notna(chance_r2_results[cell_idx]):\n",
    "                            chance_score = chance_r2_results[cell_idx]\n",
    "                        else:\n",
    "                            chance_score = compute_chance_r2(cell_idx, df, model, kf, n_shuffles=100)\n",
    "                    else:\n",
    "                        # For multi-cell combinations, compute new surrogate\n",
    "                        chance_score = compute_multi_cell_chance_r2(cell_combination, df, model, kf, n_shuffles=100)\n",
    "                    \n",
    "                    multi_cell_chance_r2[n_cells].append(chance_score)\n",
    "                pbar.update(1)\n",
    "\n",
    "print(\"\\nSurrogate R² computation completed!\")\n",
    "print(\"Number of surrogate combinations by group size:\")\n",
    "print(\"-\" * 50)\n",
    "for n_cells, scores in multi_cell_chance_r2.items():\n",
    "    valid_scores = [s for s in scores if not np.isnan(s)]\n",
    "    print(f\"{n_cells} cells: {len(valid_scores)} valid surrogates out of {len(scores)} total\")\n",
    "\n",
    "# Statistical comparison between actual and surrogate multi-cell decoding\n",
    "print(\"\\nStatistical comparisons - Actual vs Surrogate:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for n_cells in range(1, 6):\n",
    "    actual_scores = [s for s in r2_data[n_cells] if not np.isnan(s)]\n",
    "    surrogate_scores = [s for s in multi_cell_chance_r2[n_cells] if not np.isnan(s)]\n",
    "    \n",
    "    if len(actual_scores) > 0 and len(surrogate_scores) > 0:\n",
    "        # Mann-Whitney U test (independent samples)\n",
    "        stat, p_val = mannwhitneyu(actual_scores, surrogate_scores, alternative='two-sided')\n",
    "        effect_size = (np.mean(actual_scores) - np.mean(surrogate_scores)) / np.std(np.concatenate([actual_scores, surrogate_scores]))\n",
    "        \n",
    "        print(f\"{n_cells} cells:\")\n",
    "        print(f\"  Actual mean ± std: {np.mean(actual_scores):.4f} ± {np.std(actual_scores):.4f}\")\n",
    "        print(f\"  Surrogate mean ± std: {np.mean(surrogate_scores):.4f} ± {np.std(surrogate_scores):.4f}\")\n",
    "        print(f\"  Mann-Whitney U p-value: {p_val:.3e}\")\n",
    "        print(f\"  Effect size (Cohen's d): {effect_size:.3f}\")\n",
    "        print(f\"  Significant: {'Yes' if p_val < 0.05 else 'No'}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"{n_cells} cells: Insufficient data for comparison\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573a3db1",
   "metadata": {},
   "source": [
    "# Representative cell decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b099fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_idx = 74\n",
    "start_idx = 7000\n",
    "end_idx = 8000\n",
    "\n",
    "# Get original data and extract the segment\n",
    "original_firing = np.array(df.loc[cell_idx, 'Firing_Rate'])\n",
    "original_speed = np.array(df.loc[cell_idx, 'Speed_Vector'])\n",
    "\n",
    "# Smooth original data\n",
    "original_firing = gaussian_filter1d(original_firing, sigma=10)\n",
    "original_speed = gaussian_filter1d(original_speed, sigma=10)\n",
    "\n",
    "# Extract the segment\n",
    "firing_segment = original_firing[start_idx:end_idx]\n",
    "speed_segment = original_speed[start_idx:end_idx]\n",
    "\n",
    "# Apply winsorization to the segment\n",
    "firing_win, speed_win = winsorize_data(firing_segment, speed_segment)\n",
    "\n",
    "# Fit model and predict\n",
    "linear_pipeline.fit(firing_win.reshape(-1, 1), speed_win)\n",
    "speed_decoded = linear_pipeline.predict(firing_win.reshape(-1, 1))\n",
    "\n",
    "# Convert to regular numpy arrays\n",
    "y_win = np.asarray(speed_win)\n",
    "predictions = np.asarray(speed_decoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ee6bec",
   "metadata": {},
   "source": [
    "# Multi-cell decoding stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bce1616",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_r2_by_cell = results_df.set_index('Cell_Index')['Mean_R2']\n",
    "\n",
    "# Use CCG_Value instead of Optimal_Lag to define positive/negative cells\n",
    "pos_idx = df[(df['Locomotion_Cell'] == True) & (df['CCG_Value'] >= 0)].index\n",
    "neg_idx = df[(df['Locomotion_Cell'] == True) & (df['CCG_Value'] < 0)].index\n",
    "\n",
    "pos_r2 = mean_r2_by_cell.reindex(pos_idx).dropna().values\n",
    "neg_r2 = mean_r2_by_cell.reindex(neg_idx).dropna().values\n",
    "\n",
    "# Statistical test: Mann-Whitney U (nonparametric, two independent groups)\n",
    "pos_neg_p = np.nan\n",
    "pos_neg_stat = np.nan\n",
    "if len(pos_r2) > 0 and len(neg_r2) > 0:\n",
    "    pos_neg_stat, pos_neg_p = mannwhitneyu(pos_r2, neg_r2, alternative='two-sided')\n",
    "    print(f\"Positive vs Negative CCG Mann-Whitney U p-value: {pos_neg_p:.3e}, U={pos_neg_stat:.3f}\")\n",
    "    print(f\"Positive CCG cells: {len(pos_r2)}, Negative CCG cells: {len(neg_r2)}\")\n",
    "else:\n",
    "    print(\"Positive vs Negative CCG comparison: not enough data (pos:\", len(pos_r2), \"neg:\", len(neg_r2), \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f347a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_numbers = np.arange(1, 6)\n",
    "actual_box_data = [r2_data[i] for i in cell_numbers]\n",
    "\n",
    "# Statistical comparisons between consecutive actual data points\n",
    "actual_p_values = []\n",
    "for i in range(len(actual_box_data) - 1):\n",
    "    stat, p_val = mannwhitneyu(actual_box_data[i], actual_box_data[i + 1])\n",
    "    actual_p_values.append(p_val)\n",
    "    print(f\"Actual multi-cell {i+1} vs {i+2} cells p-value: {p_val:.3e}\")\n",
    "\n",
    "# Add comparison significance bars between actual and surrogate for each cell number\n",
    "multi_cell_comparisons_p = []\n",
    "for n_cells in cell_numbers:\n",
    "    actual_scores = [s for s in r2_data[n_cells] if not np.isnan(s)]\n",
    "    surrogate_scores = [s for s in multi_cell_chance_r2[n_cells] if not np.isnan(s)]\n",
    "    \n",
    "    if len(actual_scores) > 0 and len(surrogate_scores) > 0:\n",
    "        stat, p_val = mannwhitneyu(actual_scores, surrogate_scores, alternative='two-sided')\n",
    "        multi_cell_comparisons_p.append(p_val)\n",
    "        print(f\"Multi-cell {n_cells} cells - Actual vs Surrogate p-value: {p_val:.3e}\")\n",
    "    else:\n",
    "        multi_cell_comparisons_p.append(np.nan)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cc2433",
   "metadata": {},
   "source": [
    "# Export the data for figure 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a12edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export all the necessary data for plotting\n",
    "figure_data = {\n",
    "    # Example decoding data\n",
    "    'y_win': y_win,\n",
    "    'predictions': predictions,\n",
    "    \n",
    "    # Cell type comparison data\n",
    "    'fsi_data': fsi_data,\n",
    "    'msn_data': msn_data,\n",
    "    'neuron_ttest_pvalue': neuron_ttest.pvalue,\n",
    "    \n",
    "    # Locomotion cell comparison data\n",
    "    'other_data': other_data,\n",
    "    'speed_data': speed_data,\n",
    "    'loco_ttest_pvalue': loco_ttest.pvalue,\n",
    "    \n",
    "    # Speed cells vs surrogate data\n",
    "    'speed_r2': speed_data,\n",
    "    'surrogate_data': speed_cell_chance_r2.values,\n",
    "    'chance_comparison_pvalue': chance_comparison_pvalue,\n",
    "    \n",
    "    # Positive vs negative lag data\n",
    "    'pos_r2': pos_r2,\n",
    "    'neg_r2': neg_r2,\n",
    "    'pos_neg_p': pos_neg_p,\n",
    "    \n",
    "    # Multi-cell decoding data\n",
    "    'r2_data': r2_data,\n",
    "    'multi_cell_chance_r2': multi_cell_chance_r2,\n",
    "    'actual_p_values': actual_p_values,\n",
    "    'multi_cell_comparisons_p': multi_cell_comparisons_p,\n",
    "    \n",
    "    # Additional metadata\n",
    "    'cell_numbers': cell_numbers.tolist(),\n",
    "    'positions_actual': (np.arange(1, 11, 2) - 0.3).tolist(),\n",
    "    'positions_surrogate': (np.arange(1, 11, 2) + 0.3).tolist()\n",
    "}\n",
    "\n",
    "# Save as pickle file for easy loading\n",
    "with open('figure_data_final_acabapeloamordedeus.pkl', 'wb') as f:\n",
    "    pickle.dump(figure_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f023837a",
   "metadata": {},
   "source": [
    "# Figure (before processing in image editor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3214f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "with open('figure_data_final.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Extract all variables\n",
    "y_win = np.array(data['y_win'])\n",
    "predictions = np.array(data['predictions'])\n",
    "fsi_data = np.array(data['fsi_data'])\n",
    "msn_data = np.array(data['msn_data'])\n",
    "neuron_ttest_pvalue = data['neuron_ttest_pvalue']\n",
    "other_data = np.array(data['other_data'])\n",
    "speed_data = np.array(data['speed_data'])\n",
    "loco_ttest_pvalue = data['loco_ttest_pvalue']\n",
    "speed_r2 = np.array(data['speed_r2'])\n",
    "surrogate_data = np.array(data['surrogate_data'])\n",
    "chance_comparison_pvalue = data['chance_comparison_pvalue']\n",
    "pos_r2 = np.array(data['pos_r2'])\n",
    "neg_r2 = np.array(data['neg_r2'])\n",
    "pos_neg_p = data['pos_neg_p']\n",
    "r2_data = data['r2_data']\n",
    "multi_cell_chance_r2 = data['multi_cell_chance_r2']\n",
    "actual_p_values = data['actual_p_values']\n",
    "multi_cell_comparisons_p = data['multi_cell_comparisons_p']\n",
    "cell_numbers = np.array(data['cell_numbers'])\n",
    "positions_actual = np.array(data['positions_actual'])\n",
    "positions_surrogate = np.array(data['positions_surrogate'])\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"FSI vs MSN p-value: {neuron_ttest_pvalue}\")\n",
    "print(f\"Speed vs Other p-value: {loco_ttest_pvalue}\")\n",
    "print(f\"Speed vs Surrogate p-value: {chance_comparison_pvalue}\")\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"FSI vs MSN p-value: {neuron_ttest_pvalue}\")\n",
    "print(f\"Speed vs Other p-value: {loco_ttest_pvalue}\")\n",
    "print(f\"Speed vs Surrogate p-value: {chance_comparison_pvalue}\")\n",
    "\n",
    "# Create figure with the new layout\n",
    "fig = plt.figure(figsize=(12, 8))  # Reduced height\n",
    "\n",
    "# Outer GridSpec has 2 rows: top and bottom with increased spacing\n",
    "outer_gs = GridSpec(2, 1, height_ratios=[1, 1], figure=fig, hspace=0.3)  # Increased hspace for more whitespace\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# First row: 2 columns (75% left, 25% right)\n",
    "###############################################################################\n",
    "gs_top = GridSpecFromSubplotSpec(1, 2, subplot_spec=outer_gs[0], width_ratios=[3, 1])\n",
    "\n",
    "# --- Speed Decoding (Row 1, Column 1) ---\n",
    "ax_speed = fig.add_subplot(gs_top[0, 0])\n",
    "ax_speed.plot(y_win, label='Actual', alpha=0.7, color='black', linewidth=2.5)\n",
    "ax_speed.plot(predictions, label='Decoded', alpha=0.7, color='red', linewidth=2.5)\n",
    "ax_speed.set_xlabel('Time (s)', fontname='Arial', fontsize=12)\n",
    "ax_speed.set_ylabel('Speed (cm/s)', fontname='Arial', fontsize=12)\n",
    "ax_speed.legend(frameon=False, prop={'family': 'Arial', 'size': 12})\n",
    "ax_speed.spines['top'].set_visible(False)\n",
    "ax_speed.spines['right'].set_visible(False)\n",
    "ax_speed.set_ylim(-0, 50)\n",
    "xticks = np.linspace(0, 1000, 6)\n",
    "xticklabels = [f'{x:g}' for x in np.linspace(0, 100, 6)]\n",
    "ax_speed.set_xticks(xticks)\n",
    "ax_speed.set_xticklabels(xticklabels, fontsize=12)\n",
    "ax_speed.text(-0.1, 1.05, 'A', fontsize=14, fontweight='bold', fontname='Arial', transform=ax_speed.transAxes)\n",
    "\n",
    "# --- Cell Type Analysis (Row 1, Column 2) ---\n",
    "ax_cell = fig.add_subplot(gs_top[0, 1])\n",
    "bp_cell = ax_cell.boxplot([fsi_data, msn_data], showfliers=False, notch=False, patch_artist=True)\n",
    "bp_cell['boxes'][0].set_facecolor('none')\n",
    "bp_cell['boxes'][0].set_edgecolor('#FC4366')\n",
    "bp_cell['boxes'][1].set_facecolor('none')\n",
    "bp_cell['boxes'][1].set_edgecolor('#AEB2FF')\n",
    "ax_cell.scatter([1.2] * len(fsi_data), fsi_data, alpha=0.5, color='#FC4366')\n",
    "ax_cell.scatter([1.8] * len(msn_data), msn_data, alpha=0.5, color='#AEB2FF')\n",
    "ax_cell.set_ylabel('Decoding Accuracy', fontname='Arial', fontsize=12)\n",
    "ax_cell.set_xticks([1, 2])\n",
    "ax_cell.set_xticklabels(['FSI', 'MSN'], fontname='Arial', fontsize=12)\n",
    "ax_cell.spines['top'].set_visible(False)\n",
    "ax_cell.spines['right'].set_visible(False)\n",
    "for median in bp_cell['medians']:\n",
    "    median.set_color('black')\n",
    "for whisker in bp_cell['whiskers']:\n",
    "    whisker.set_color(whisker.get_color())\n",
    "for cap in bp_cell['caps']:\n",
    "    cap.set_color(cap.get_color())\n",
    "y_max_cell = max(np.max(fsi_data), np.max(msn_data))\n",
    "bar_height_cell = y_max_cell + 0.02\n",
    "ax_cell.plot([1, 2], [bar_height_cell, bar_height_cell], '-k', linewidth=1)\n",
    "ax_cell.plot([1, 1], [bar_height_cell - 0.01, bar_height_cell], '-k', linewidth=1)\n",
    "ax_cell.plot([2, 2], [bar_height_cell - 0.01, bar_height_cell], '-k', linewidth=1)\n",
    "if neuron_ttest_pvalue < 0.05:\n",
    "    ax_cell.text(1.5, bar_height_cell + 0.01, '*', ha='center', va='bottom', fontsize=14)\n",
    "else:\n",
    "    ax_cell.text(1.5, bar_height_cell + 0.01, 'n.s.', ha='center', va='bottom', fontsize=14)\n",
    "\n",
    "ax_cell.text(-0.4, 1.05, 'B', fontsize=14, fontweight='bold', fontname='Arial', transform=ax_cell.transAxes)\n",
    "\n",
    "###############################################################################\n",
    "# Second row: 4 columns (20%, 20%, 20%, 40%)\n",
    "###############################################################################\n",
    "gs_bottom = GridSpecFromSubplotSpec(1, 4, subplot_spec=outer_gs[1], width_ratios=[1, 1, 1, 2])\n",
    "\n",
    "# --- Locomotion Cell Analysis (Row 2, Column 1) ---\n",
    "ax_loco = fig.add_subplot(gs_bottom[0, 0])\n",
    "bp_loco = ax_loco.boxplot([other_data, speed_data], showfliers=False, notch=False, patch_artist=True)\n",
    "bp_loco['boxes'][0].set_facecolor('none')\n",
    "bp_loco['boxes'][0].set_edgecolor('gray')\n",
    "bp_loco['boxes'][1].set_facecolor('none')\n",
    "bp_loco['boxes'][1].set_edgecolor('#37a259')\n",
    "ax_loco.scatter([1.2] * len(other_data), other_data, alpha=0.5, color='gray')\n",
    "ax_loco.scatter([1.8] * len(speed_data), speed_data, alpha=0.5, color='#37a259')\n",
    "ax_loco.set_ylabel('Decoding Accuracy', fontname='Arial', fontsize=12)\n",
    "ax_loco.set_xticks([1, 2])\n",
    "ax_loco.set_xticklabels(['Other', 'Speed'], fontname='Arial', fontsize=12)\n",
    "ax_loco.spines['top'].set_visible(False)\n",
    "ax_loco.spines['right'].set_visible(False)\n",
    "for median in bp_loco['medians']:\n",
    "    median.set_color('black')\n",
    "for whisker in bp_loco['whiskers']:\n",
    "    whisker.set_color(whisker.get_color())\n",
    "for cap in bp_loco['caps']:\n",
    "    cap.set_color(cap.get_color())\n",
    "if loco_ttest_pvalue < 0.05:\n",
    "    y_max_loco = max(np.max(other_data), np.max(speed_data))\n",
    "    bar_height_loco = y_max_loco + 0.02\n",
    "    ax_loco.plot([1, 2], [bar_height_loco, bar_height_loco], '-k', linewidth=1)\n",
    "    ax_loco.plot([1, 1], [bar_height_loco - 0.01, bar_height_loco], '-k', linewidth=1)\n",
    "    ax_loco.plot([2, 2], [bar_height_loco - 0.01, bar_height_loco], '-k', linewidth=1)\n",
    "    ax_loco.text(1.5, bar_height_loco + 0.01, '*', ha='center', va='bottom', fontsize=12)\n",
    "    \n",
    "ax_loco.text(-0.1, 1.05, 'C', fontsize=14, fontweight='bold', fontname='Arial', transform=ax_loco.transAxes)\n",
    "\n",
    "# --- Speed Cells vs Surrogates (Row 2, Column 2) ---\n",
    "ax_new = fig.add_subplot(gs_bottom[0, 1])\n",
    "bp_new = ax_new.boxplot([speed_r2, surrogate_data], showfliers=False, notch=False, patch_artist=True)\n",
    "bp_new['boxes'][0].set_facecolor('none')\n",
    "bp_new['boxes'][0].set_edgecolor('#37a259')\n",
    "bp_new['boxes'][1].set_facecolor('none')\n",
    "bp_new['boxes'][1].set_edgecolor('gray')\n",
    "ax_new.scatter([1.2] * len(speed_r2), speed_r2, alpha=0.5, color='#37a259')\n",
    "ax_new.scatter([1.8] * len(surrogate_data), surrogate_data, alpha=0.5, color='gray')\n",
    "ax_new.set_ylabel('Decoding Accuracy', fontname='Arial', fontsize=12)\n",
    "ax_new.set_xticks([1, 2])\n",
    "ax_new.set_xticklabels(['Speed Cells', 'Surrogate'], fontname='Arial', fontsize=12)\n",
    "ax_new.spines['top'].set_visible(False)\n",
    "ax_new.spines['right'].set_visible(False)\n",
    "for median in bp_new['medians']:\n",
    "    median.set_color('black')\n",
    "for whisker in bp_new['whiskers']:\n",
    "    whisker.set_color(whisker.get_color())\n",
    "for cap in bp_new['caps']:\n",
    "    cap.set_color(cap.get_color())\n",
    "y_max_new = max(np.max(speed_r2), np.max(surrogate_data))\n",
    "bar_height_new = y_max_new + 0.02\n",
    "ax_new.plot([1, 2], [bar_height_new, bar_height_new], '-k', linewidth=1)\n",
    "ax_new.plot([1, 1], [bar_height_new - 0.01, bar_height_new], '-k', linewidth=1)\n",
    "ax_new.plot([2, 2], [bar_height_new - 0.01, bar_height_new], '-k', linewidth=1)\n",
    "if chance_comparison_pvalue < 0.05:\n",
    "    ax_new.text(1.5, bar_height_new + 0.01, '*', ha='center', va='bottom', fontsize=12)\n",
    "else:\n",
    "    ax_new.text(1.5, bar_height_new + 0.01, 'n.s.', ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "ax_new.text(-0.1, 1.05, 'D', fontsize=14, fontweight='bold', fontname='Arial', transform=ax_new.transAxes)\n",
    "\n",
    "# --- Positive vs Negative Optimal_Lag comparison (Row 2, Column 3) ---\n",
    "ax_pos_neg = fig.add_subplot(gs_bottom[0, 2])\n",
    "if len(pos_r2) + len(neg_r2) > 0:\n",
    "    bp_pn = ax_pos_neg.boxplot([pos_r2, neg_r2], showfliers=False, patch_artist=True)\n",
    "    colors_pn = ['#2ca02c', '#d62728']  # green for positive, red for negative\n",
    "    for patch, color in zip(bp_pn['boxes'], colors_pn):\n",
    "        patch.set_facecolor('none')\n",
    "        patch.set_edgecolor(color)\n",
    "    # scatter individual points with slight jitter\n",
    "    ax_pos_neg.scatter(np.random.normal(1, 0.04, size=len(pos_r2)), pos_r2, color=colors_pn[0], alpha=0.6, s=12)\n",
    "    ax_pos_neg.scatter(np.random.normal(2, 0.04, size=len(neg_r2)), neg_r2, color=colors_pn[1], alpha=0.6, s=12)\n",
    "\n",
    "    ax_pos_neg.set_xticks([1, 2])\n",
    "    ax_pos_neg.set_xticklabels(['Lag > 0', 'Lag < 0'], fontname='Arial', fontsize=12)\n",
    "    ax_pos_neg.set_ylabel('Decoding Accuracy', fontsize=12)\n",
    "    ax_pos_neg.spines['top'].set_visible(False)\n",
    "    ax_pos_neg.spines['right'].set_visible(False)\n",
    "\n",
    "    # annotate significance\n",
    "    combined = np.concatenate([pos_r2, neg_r2]) if (len(pos_r2)+len(neg_r2))>0 else np.array([0.0])\n",
    "    y_max_pn = np.nanmax(combined) if combined.size>0 else 0.0\n",
    "    bar_h = y_max_pn + 0.02\n",
    "    ax_pos_neg.plot([1, 2], [bar_h, bar_h], '-k', linewidth=1)\n",
    "    ax_pos_neg.plot([1, 1], [bar_h - 0.01, bar_h], '-k', linewidth=1)\n",
    "    ax_pos_neg.plot([2, 2], [bar_h - 0.01, bar_h], '-k', linewidth=1)\n",
    "    if not np.isnan(pos_neg_p):\n",
    "        sig_text = '*' if pos_neg_p < 0.05 else 'n.s.'\n",
    "        ax_pos_neg.text(1.5, bar_h + 0.01, sig_text, ha='center', va='bottom', fontsize=12)\n",
    "else:\n",
    "    ax_pos_neg.text(0.5, 0.5, 'No data for positive vs negative lag comparison', ha='center', va='center', fontsize=10)\n",
    "\n",
    "ax_pos_neg.text(-0.1, 1.05, 'E', fontsize=14, fontweight='bold', fontname='Arial', transform=ax_pos_neg.transAxes)\n",
    "\n",
    "# --- Decoding with Multiple Cells INCLUDING SURROGATES (Row 2, Column 4) ---\n",
    "ax_multi = fig.add_subplot(gs_bottom[0, 3])\n",
    "\n",
    "# Prepare actual and surrogate data for boxplots\n",
    "actual_box_data = [r2_data[i] for i in cell_numbers]\n",
    "surrogate_box_data = [multi_cell_chance_r2[i] for i in cell_numbers]\n",
    "\n",
    "# Plot actual data (green)\n",
    "bp_actual = ax_multi.boxplot(actual_box_data, positions=positions_actual, widths=0.4,\n",
    "                            showfliers=False, patch_artist=True, \n",
    "                            boxprops=dict(facecolor='none', edgecolor='#37a259'),\n",
    "                            whiskerprops=dict(color='#37a259'),\n",
    "                            capprops=dict(color='#37a259'))\n",
    "\n",
    "# Plot surrogate data (gray)\n",
    "bp_surrogate = ax_multi.boxplot(surrogate_box_data, positions=positions_surrogate, widths=0.4,\n",
    "                               showfliers=False, patch_artist=True,\n",
    "                               boxprops=dict(facecolor='none', edgecolor='gray'),\n",
    "                               whiskerprops=dict(color='gray'),\n",
    "                               capprops=dict(color='gray'))\n",
    "\n",
    "# Set medians to black for both\n",
    "for median in bp_actual['medians']:\n",
    "    median.set_color('black')\n",
    "for median in bp_surrogate['medians']:\n",
    "    median.set_color('black')\n",
    "\n",
    "# Add median line and dots for actual data (green) - positioned slightly to the left\n",
    "median_offset = -0.45  # Offset to move circles to the left of boxplots\n",
    "medians_actual = [median.get_ydata()[0] for median in bp_actual['medians']]\n",
    "ax_multi.plot(positions_actual + median_offset, medians_actual, color='#37a259', alpha=0.7, linewidth=2)\n",
    "ax_multi.scatter(positions_actual + median_offset, medians_actual, color='#37a259', zorder=5, s=30)\n",
    "\n",
    "# Add significance bars for actual vs actual comparison\n",
    "for i, p_val in enumerate(actual_p_values):\n",
    "    x1, x2 = positions_actual[i], positions_actual[i + 1]\n",
    "    # Find the highest point among the two groups being compared\n",
    "    y_max_comp = max(np.max(actual_box_data[i]), np.max(actual_box_data[i + 1]))\n",
    "    bar_height_comp = y_max_comp + 0.15  # Reduced from 0.25 to bring bars down\n",
    "    \n",
    "    ax_multi.plot([x1, x2], [bar_height_comp, bar_height_comp], '-k', linewidth=0.8)\n",
    "    ax_multi.plot([x1, x1], [bar_height_comp - 0.01, bar_height_comp], '-k', linewidth=0.8)\n",
    "    ax_multi.plot([x2, x2], [bar_height_comp - 0.01, bar_height_comp], '-k', linewidth=0.8)\n",
    "    \n",
    "    sig_text = '*' if p_val < 0.05 else 'n.s.'\n",
    "    ax_multi.text((x1 + x2) / 2, bar_height_comp + 0.01, sig_text, \n",
    "                 ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Add significance indicators between actual and surrogate for each cell number\n",
    "for i, (pos_act, pos_sur, p_val) in enumerate(zip(positions_actual, positions_surrogate, multi_cell_comparisons_p)):\n",
    "    if not np.isnan(p_val):\n",
    "        # Get max height for this comparison\n",
    "        actual_data = actual_box_data[i]\n",
    "        surrogate_points = surrogate_box_data[i]\n",
    "        \n",
    "        if len(actual_data) > 0 and len(surrogate_points) > 0:\n",
    "            y_max_comp = max(np.max(actual_data), np.max(surrogate_points))\n",
    "            bar_height_comp = y_max_comp + 0.1  # Lower position for actual vs surrogate\n",
    "            \n",
    "            # Draw comparison bar\n",
    "            ax_multi.plot([pos_act, pos_sur], [bar_height_comp, bar_height_comp], '-k', linewidth=0.8)\n",
    "            ax_multi.plot([pos_act, pos_act], [bar_height_comp - 0.01, bar_height_comp], '-k', linewidth=0.8)\n",
    "            ax_multi.plot([pos_sur, pos_sur], [bar_height_comp - 0.01, bar_height_comp], '-k', linewidth=0.8)\n",
    "            \n",
    "            # Add significance text (single asterisk regardless of p-value)\n",
    "            sig_text = '*' if p_val < 0.05 else 'n.s.'\n",
    "            ax_multi.text((pos_act + pos_sur) / 2, bar_height_comp + 0.01, sig_text, \n",
    "                         ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Add legend - moved to center right\n",
    "legend_elements = [Patch(facecolor='none', edgecolor='#37a259', label='Actual'),\n",
    "                   Patch(facecolor='none', edgecolor='gray', label='Surrogate')]\n",
    "ax_multi.legend(handles=legend_elements, loc='center right', bbox_to_anchor=(1, 0.4), frameon=False, fontsize=10)\n",
    "\n",
    "\n",
    "ax_multi.set_xlabel('Number of Cells', fontname='Arial', fontsize=12)\n",
    "ax_multi.set_ylabel('Decoding Accuracy', fontname='Arial', fontsize=12)\n",
    "ax_multi.set_xticks(np.arange(1, 11, 2))\n",
    "ax_multi.set_xticklabels(cell_numbers, fontsize=12)\n",
    "ax_multi.spines['top'].set_visible(False)\n",
    "ax_multi.spines['right'].set_visible(False)\n",
    "ax_multi.set_xlim(0, 10)\n",
    "\n",
    "ax_multi.text(-0.1, 1.05, 'F', fontsize=14, fontweight='bold', fontname='Arial', transform=ax_multi.transAxes)\n",
    "\n",
    "# Save and show the figure\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.1)  # Reduced hspace for less whitespace\n",
    "plt.savefig('figure7.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure saved as 'figure7.png'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decoding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
